{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><center><img src=\"img/mlhep-logo-transparent.png\" width=\"400\"></center></td>\n",
    "    <td><h1><center>The Sixth Machine Learning in High Energy Physics Summer School (MLHEP) 2020</center></h1></td>\n",
    "  </tr>\n",
    " </table>\n",
    "\n",
    "<h1><center>Seminar</center></h1>\n",
    "<h2><center>Feature engineering, importance and selection</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# About\n",
    "\n",
    "The goal of this seminar is to demonstrate several ways how to estimate feature importances and to use them for the best feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.testing as np_testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 1: Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "UCI MAGIC dataset: https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).\n",
    "\n",
    "Features description:\n",
    "- **Length:** continuous # major axis of ellipse [mm]\n",
    "- **Width:** continuous # minor axis of ellipse [mm]\n",
    "- **Size:** continuous # 10-log of sum of content of all pixels [in #phot]\n",
    "- **Conc:** continuous # ratio of sum of two highest pixels over fSize [ratio]\n",
    "- **Conc1:** continuous # ratio of highest pixel over fSize [ratio]\n",
    "- **Asym:** continuous # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- **M3Long:** continuous # 3rd root of third moment along major axis [mm]\n",
    "- **M3Trans:** continuous # 3rd root of third moment along minor axis [mm]\n",
    "- **Alpha:** continuous # angle of major axis with vector to origin [deg]\n",
    "- **Dist:** continuous # distance from origin to center of ellipse [mm]\n",
    "- **Label:** g,h # gamma (signal), hadron (background)\n",
    "\n",
    "g = gamma (signal): 12332 \\\n",
    "h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = np.array([\"Length\", \"Width\", \"Size\", \"Conc\", \"Conc1\", \"Asym\", \"M3Long\", \"M3Trans\", \"Alpha\", \"Dist\"])\n",
    "\n",
    "data = pd.read_csv(\"data/MAGIC/magic04.data\", header=None, names=list(f_names)+[\"Label\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a matrix of input features\n",
    "X = data[f_names].values\n",
    "\n",
    "# prepare a vector of true labels\n",
    "y = 1 * (data['Label'].values == \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test subsamples to fit and test classifiers\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Gradient Boosting based feature importances\n",
    "\n",
    "<center><img src=\"img/tree.png\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let $T(f)$ be the set of all nodes which use feature $f$ to make split. Then, feature importance $Imp(f)$ of $f$:\n",
    "\n",
    "$$\n",
    "Imp(f) = \\sum_{t \\in T(f)} n_t \\Delta I(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta I(t) = I(t) - \\sum_{c \\in children} \\frac{n_c}{n_t} I(c)\n",
    "$$\n",
    "\n",
    "where\n",
    "- $n_{t}$ - number of objects in node $t$;\n",
    "- $I(t)$ â€“ impurity function (gini, cross-entropy, MSE) value for the node.\n",
    "\n",
    "Feature importances estimated by each tree in an ensemble are averaged over all trees in this ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will be used just to plot feature importances\n",
    "\n",
    "def plot_feature_importances(f_imps, f_names, title=\"\"):\n",
    "    f_imps = np.array(f_imps)\n",
    "    f_names = np.array(f_names)\n",
    "    sort_inds = np.argsort(f_imps)\n",
    "    yy = np.arange(len(f_imps)).astype(np.int)\n",
    "    plt.barh(yy, f_imps[sort_inds])\n",
    "    plt.yticks(yy, f_names[sort_inds], size=14)\n",
    "    plt.xticks(size=14)\n",
    "    plt.xlabel(\"Feature importance\", size=14)\n",
    "    plt.title(title, size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import quality metrics and GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define a classifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)\n",
    "\n",
    "# fit it using the train subsample\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# get predictions for the test subsample\n",
    "y_test_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# compute roc auc score on the test\n",
    "roc_auc_gb = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "print(\"Test ROC AUC: \", roc_auc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature imporatnces\n",
    "f_imps_gb = gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the feature importances\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linear model based feature importances\n",
    "\n",
    "Consider a linear model with regularization ($L_1$ or $L_2$ penalty):\n",
    "\n",
    "$$\n",
    "\\hat{y}=w_0 + w_1 f_1+ w_2 f_2 + ... + w_k f_k\n",
    "$$\n",
    "\n",
    "If features are normalized (have the same ranges), feature importance $Imp(f_i)$ of $f_i$ is equal to:\n",
    "\n",
    "$$\n",
    "Imp(f_i) = | w_i |\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1\n",
    "Estimate feature importacnes using linear model as it is described above.\n",
    "\n",
    "**Hints:** use `StandardScaler()` to normalize feature values. Also, use `LogisticRegression(solver='liblinear', penalty='l2', C=C, random_state=11)` for the linear model. To get values of the model coefficients use `<model>.coef_[0]` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f46624fd667e131099f417d1762c912",
     "grade": false,
     "grade_id": "ba9090_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_feature_imp_with_lin_mod(X_train, y_train, C=1.0):\n",
    "    \"\"\"\n",
    "    Estimate feature importances using linear model with regularization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train: numpy.ndarray\n",
    "        Object features matrix.\n",
    "    y_train: numpy.array\n",
    "        Vector of true class labels.\n",
    "    C: float\n",
    "        Inverse of regularization strength; must be a positive float.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f_imps_lin: numpy.array\n",
    "        Estimated feature importances.\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize feature values\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_ss = ss.transform(X_train)\n",
    "\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return f_imps_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imps_lin = get_feature_imp_with_lin_mod(X_train, y_train, C=1.)\n",
    "f_imps_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Expected output:\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "array([1.23276898, 0.08849417, 0.31007411, 0.07866152, 0.69042639,\n",
    "       0.01030818, 0.31858178, 0.01445776, 1.20855327, 0.0711564 ])\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d56c2d4557be2d768b353f4253dedcf9",
     "grade": true,
     "grade_id": "ba9090",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the feature importances\n",
    "plot_feature_importances(f_imps_lin, f_names, \"Linear model\")\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Do you have any ideas why the feature importances are so different for these two models? Let's compare quality of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize feature values\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_ss = ss.transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)\n",
    "\n",
    "# fit a linear model with regularization\n",
    "linclf = LogisticRegression(solver='liblinear', penalty='l2', C=1.0, random_state=11)\n",
    "linclf.fit(X_train_ss, y_train)\n",
    "\n",
    "# get predictions for the test subsample\n",
    "y_test_proba = linclf.predict_proba(X_test_ss)[:, 1]\n",
    "\n",
    "# compute roc auc score on the test\n",
    "roc_auc_lin = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"Test ROC AUC (GB)    : \", roc_auc_gb)\n",
    "print(\"Test ROC AUC (LogReg): \", roc_auc_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## General method\n",
    "\n",
    "<center><img src=\"img/general.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Algorithm:\n",
    "- Train your model\n",
    "- Calculate quality measure $Q_0$ on the test set\n",
    "- For a feature $f$:\n",
    " - Replace given values with random values from the same distribution (perform random shuffling)\n",
    " - Calculate quality measure $Q_f$ on the test set\n",
    " - Estimate feature importance: $Imp(f)=Q_0 - Q_f$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 2\n",
    "\n",
    "Estimate feature importances using general algorithm described above. \n",
    "\n",
    "**Hint:** to shuffle values of one feature use `numpy.random.RandomState(42).shuffle()`, for an example: `X[:, i] = np.random.RandomState(42).shuffle(X[:, i])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model that we will use to estimate feature importances\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)\n",
    "\n",
    "# fit the model on the train sample\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ea4167c7e90f0759a07b4c42988707",
     "grade": false,
     "grade_id": "1df626_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_imp_general(X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Estimate feature importances using linear model with regularization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_test: numpy.ndarray\n",
    "        Object features matrix.\n",
    "    y_test: numpy.array\n",
    "        Vector of true class labels.\n",
    "    model: object\n",
    "        A classifier fitted on the train sample\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f_imps_gen: numpy.array\n",
    "        Estimated feature importances.\n",
    "    \"\"\"\n",
    "    \n",
    "    # define a list for the feature importances\n",
    "    f_imps_gen = []\n",
    "\n",
    "    # calculate the base quality value according to the algorithm\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    q_0 = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    # for each feature in the sample estimate its importance\n",
    "    for i in range(X_test.shape[1]):\n",
    "        \n",
    "        # do not forget to make a copy of X_test!\n",
    "        X_test_copy = X_test.copy()\n",
    "        \n",
    "        # shuffle values of the i-th feature\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        # calculate quality metric value\n",
    "        X_test_copy = np.nan_to_num(X_test_copy)\n",
    "        y_test_proba = model.predict_proba(X_test_copy)[:, 1]\n",
    "        q_f = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        # estimate importance of the feature\n",
    "        imp = q_0 - q_f\n",
    "        f_imps_gen.append(imp)\n",
    "        \n",
    "    return np.array(f_imps_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imps_gen = get_feature_imp_general(X_test, y_test, model)\n",
    "f_imps_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Expected output (approximately):\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "array([0.04537013, 0.06596446, 0.08269023, 0.00817734, 0.00350842,\n",
    "       0.00091059, 0.00249184, 0.00053674, 0.11450679, 0.09304359])\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acc287bc39303e06719308ec0fa665f4",
     "grade": true,
     "grade_id": "1df626",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(f_imps_gen, f_names, \"General\")\n",
    "plot_feature_importances(f_imps_gb, f_names, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 2: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Recursive feature elimination\n",
    "\n",
    "- Train a model on the full set of features\n",
    "- Estimate feature importance (based on the model)\n",
    "- Remove the least important feature\n",
    "- Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 3\n",
    "Implement recursive feature elimination using `model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=11)` as a model.\n",
    "\n",
    "**Hint:** use feature importances estimated by the model `model.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "517ca439364bfa083ee2024cfc41a6bd",
     "grade": false,
     "grade_id": "70c60f_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# make copies for further steps\n",
    "X_train_curr = X_train.copy()\n",
    "X_test_curr  = X_test.copy()\n",
    "f_names_curr = f_names.copy()\n",
    "\n",
    "# for storing roc auc scores\n",
    "roc_auc_scores = []\n",
    "\n",
    "# eliminate feature by feature\n",
    "for i in range(X.shape[1]):\n",
    "    \n",
    "    print(\"Features: \", f_names_curr)\n",
    "    \n",
    "    # 1. fit the model using current set of festures\n",
    "    # 2. get feature importances\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # compute roc auc of the model\n",
    "    y_test_proba = model.predict_proba(X_test_curr)[:, 1]\n",
    "    auc = metrics.roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    # print and store it\n",
    "    auc = np.round(auc, 4)\n",
    "    print(\"ROC AUC: \", auc)\n",
    "    roc_auc_scores.append(auc)\n",
    "\n",
    "    # remove feature with the least importance\n",
    "    X_train_curr = X_train_curr[:, f_imps > f_imps.min()]\n",
    "    X_test_curr  = X_test_curr[:, f_imps > f_imps.min()]\n",
    "    f_names_curr = f_names_curr[f_imps > f_imps.min()]\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"Output: \", roc_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Expected output:\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "[0.9235, 0.9232, 0.9229, 0.9218, 0.9187, 0.9153, 0.9113, 0.8862, 0.8666, 0.7823]\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de3b45957523cbcce356cb048823d2a5",
     "grade": true,
     "grade_id": "70c60f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = np.arange(1, len(roc_auc_scores)+1)[::-1]\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(nf, roc_auc_scores, linewidth=3)\n",
    "plt.scatter(nf, roc_auc_scores, linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Number of features\", size=16)\n",
    "plt.ylabel(\"ROC AUC\", size=16)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.grid(b=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
